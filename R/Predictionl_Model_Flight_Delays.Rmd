---
title: "190536235_ST2195_Question5: Use the available variables to construct a model that predicts delays?"
output:
  html_document:
     df_print: paged
---
# Question 5: Use the available variables to construct a model that predicts delays?

### Install and load the library

Install and load the `reshape2`` package.
```{r}
if (!("reshape2" %in% installed.packages())) {
  install.packages("reshape2")
}

library(reshape2)
```

Install and load the `dplyr`` package.
```{r}
if (!("dplyr" %in% installed.packages())) {
  install.packages("dplyr")
}
library(dplyr)
```

Install and load the `ggthemes`` package.
```{r}
if (!("ggthemes" %in% installed.packages())) {
  install.packages("ggthemes")
}
library(ggthemes)
```

Install and load the `ggplot2`` package.
```{r}
if (!("ggplot2" %in% installed.packages())) {
  install.packages("ggplot2")
}
library(ggplot2)
```

Install and load the `tidyr`` package.
```{r}
if (!("tidyr" %in% installed.packages())) {
  install.packages("tidyr")
}
library(tidyr)
```

Install and load the `tidyverse`` package.
```{r}
if (!("tidyverse" %in% installed.packages())) {
  install.packages("tidyverse")
}
library(tidyverse)
```

Install and load the `caret`` package.
```{r}
if (!("caret" %in% installed.packages())) {
  install.packages("caret")
}
library(caret)
```

Install and load the `leaps`` package.
```{r}
if (!("leaps" %in% installed.packages())) {
  install.packages("leaps")
}
library(leaps)
```

Install and load the `corrplot`` package.
```{r}
if (!("corrplot" %in% installed.packages())) {
  install.packages("corrplot")
}
library(corrplot)
```


### Data pre-processing stage (If data has not previously load from question 1.Rmd)
Load and save csv file where header is reflected. Note: results from analysis may slightly differ due to random subset samples.
```{r}
ontime_2008 <- read.csv("D:/SIM courses/Programming/Project/2008.csv", header = TRUE)
ontime_2007 <- read.csv("D:/SIM courses/Programming/Project/2007.csv", header = TRUE)
ontime2007_2008 <- rbind(ontime_2007, ontime_2008)


airports <- airports <-read.csv("D:/SIM courses/Programming/Project/airports.csv", header = TRUE)
carriers <- read.csv("D:/SIM courses/Programming/Project/carriers.csv", header = TRUE)
planes <- read.csv("D:/SIM courses/Programming/Project/plane-data.csv", header = TRUE)
```

Randomly subset 30% of the data set due to constraint on computer system, check and remove missing values. Additionally, remove unused data frames to free up spaces.    
```{r}
ontime <- ontime2007_2008 %>% sample_frac(0.3)
class(ontime)
sum(is.na(ontime))

rm(ontime_2007, ontime_2008, ontime2007_2008)

```

Assumption made on the criteria for outliers on departure and arrival delay to be removed when it exceeds 240 minutes (4hours) based on airline policies.
```{r}
df <- ontime %>%
  rename_all(tolower) %>%
  filter(depdelay<240 & arrdelay<240)
```
References: https://www.citizensadvice.org.uk/consumer/holiday-cancellations-and-compensation/if-your-flights-delayed-or-cancelled/ 

### Data Query
#### Question 5: Use the available variables to construct a model that predicts delays?
Random number generator is set to reproduce result.
```{r}
set.seed(10)


```

Before modelling any prediction on departure delays, data needs to be visualized to check for patterns that may have exists among aircraft carriers in relation with departure and arrival delays. The data has been filtered to only include non-cancelled flights to determine its average delays among aircraft carriers.
```{r}
q5 <- df %>%
  rename_all(tolower) %>%
  inner_join(carriers, by=c('uniquecarrier' = 'Code')) %>%
  select(depdelay, arrdelay, Description, cancelled) %>%
  filter(cancelled ==0) %>%
  group_by(Description) %>%
  summarize(mean_depdelay = mean(depdelay),
            mean_arrdelay = mean(arrdelay)) %>%
  arrange(mean_depdelay)

q5_melt <- melt(q5, id.var="Description", )
q5_melt
colnames(q5_melt) <- c("carriername", "delaytypes", "delayvalues")
```

Plot to show any hidden pattern exist among carriers in relation with departure and arrival delays for 2007-2008.
```{r}
q5_plot <- ggplot(q5_melt, aes(x=delayvalues, y=carriername, fill=delaytypes)) + 
  geom_bar(stat="identity", position = "stack", alpha = 0.6) +  
  ggtitle("Departure and Arrival delays among Carriers") + 
  xlab("Average Flights Delayed (in minutes)") + 
  ylab("Carriername") +
  scale_y_discrete(label=function(y) abbreviate(y, minlength=20)) +
  theme_classic()
q5_plot
```

To determine variables that are useful in predicting departure delay model, correlation matrix has been drawn to visualize individual variables that are correlated with departure delays. Due to computer constraints, data set has been further subset into 10% from previous 30% sampled data for efficient performance.
```{r}
q6 <- df %>% rename_all(tolower) %>% sample_frac(0.01)
q6_a <- q6[,c(5:8,12:16,19:21,25:29)]
q6_a <- q6_a %>% drop_na()
q6_a <- data.frame(apply(q6_a, 2, function(x) as.numeric(as.factor(x))))
corrplot(cor(q6_a), is.corr=TRUE) 
cor(q6_a)
```


Due to flight has yet to materialize or depart, only variables that does not require actual observation to take place and can be obtained via forecasted data, are included in the model. Hence, the final variables: crsdepdelay, crsarrdelay, depdelay, carrierdelay, weatherdelay, nasdelay and lateaircraftdelay, are correlated with departure delays will be used in the prediction model and its NAs values has been dropped to facilitate pipeline machine learning algorithm and reduce errors.
```{r}
q6_final <- q6[,c(6,8,16,25:27,29)]
sum(is.na(q6_final)) 
q6_final <- q6_final %>% drop_na()
sum(is.na(q6_final))

q7 <- q6_final

length(dim(q7))
corrplot(cor(q7), is.corr=TRUE) 
cor(q7)

```

### Regression task

Install and load the `mlr3`` package.
```{r}
if (!("mlr3" %in% installed.packages())) {
  install.packages("mlr3")
}
library(mlr3)
```

Install and load the `mlr3learners`` package.
```{r}
if (!("mlr3learners" %in% installed.packages())) {
  install.packages("mlr3learners")
}
library(mlr3learners)
```

Install and load the `mlr3pipelines`` package.
```{r}
if (!("mlr3pipelines" %in% installed.packages())) {
  install.packages("mlr3pipelines")
}
library(mlr3pipelines)
```

Install and load the `mlr3tuning`` package.
```{r}
if (!("mlr3tuning" %in% installed.packages())) {
  install.packages("mlr3tuning")
}
library(mlr3tuning)
```

Set up regression task from final data selection to predict departure delays.
```{r}
task <- TaskRegr$new(id = 'q7', backend = q7, target='depdelay')
task$nrow
task$ncol
```

Hypterparameter tunning: search entire space with `grid_search`` and evaluate model 10 times.
```{r}
tuner <- tnr('grid_search')
terminator <- trm('evals', n_evals = 10)
```

Categorical factor encoding (if final features selected contains categorical data type):
```{r}
fencoder <- po("encode", method="treatment",
               affect_columns=selector_type("factor"))

```

#### Linear Regression

To ensure prediction model is generated, data has been imputed using mean for numeric or integers data types and mode (highest frequency) for categorical data types, as well as scaling to ensure equal measurement unit during prediction and combined into a graph learner. Regression Root Mean Square Error (RMSE) `regr.lm`` is used as a measure of prediction accuracy for regression model. 
```{r}
msr()  
measure <- msr('regr.rmse')

learner_rlm <- lrn('regr.lm')

gr_rlm <- po('imputemean', affect_columns=selector_type(c("numeric","integer"))) %>>%
  po('imputemode', affect_columns=selector_type("factor")) %>>%
  fencoder %>>%
  po('scale') %>>% 
  po(learner_rlm)

glrn_rlm <- GraphLearner$new(gr_rlm)
```

70% Train and 30% test set split is used to determine how well the model predicts future outcome with test set(unseen model) based on training observations (seen model). The test-set Root Mean Square Error (RMSE) is 9.41.
```{r}
n <- nrow(q7)
set.seed(200)
train_set <- sample(n, round(0.7*n))
test_set <- setdiff(1:n, train_set)


glrn_rlm$train(task, row_ids = train_set) 
glrn_rlm$predict(task, row_ids = test_set)$score(measure) # Test-set RMSE = 9.41

# Additional - show predicted values
predict_rlm <- glrn_rlm$predict(task, row_ids=test_set)
as.data.table(predict_rlm) # truth = actual observation, response = predicted observations.
```

#### Ridge regression

Combine all the necessary data cleaning and modelling: scaling, imputation and regression learner `regr.glmnet``,  into a graph learner algorithm to facilitate prediction.
```{r}
learner_rridge <- lrn('regr.glmnet')  # type of model to be used
learner_rridge$param_set$values <- list(alpha = 0)
gr_rridge <- po('imputemean', affect_columns=selector_type(c("numeric","integer"))) %>>%
  po('imputemode', affect_columns=selector_type("factor")) %>>%
  fencoder %>>%
  po('scale') %>>% 
  po(learner_rridge)
glrn_rridge <- GraphLearner$new(gr_rridge) # graph learner that consist of data cleaning and model to fit data and output its prediction.

```

Predict on train-test split. The train-set RMSE is 9.81 and the test-set RMSE is 
```{r}
glrn_rridge$train(task, row_ids = train_set)
glrn_rridge$predict(task, row_ids = train_set)$score(measure) # default lambda = 0.01, RMSE=9.81

predict_rridge <- glrn_rridge$predict(task, row_ids=test_set) # default lambda = 0.01
as.data.table(predict_rridge) # truth = actual observation, response = predicted observations.

```

Set up tuning environment `regr.glmnet.lambda`` where penalty imposed for shrinking large data sets at between 0.001 to 2. 
```{r}

tune_lambda_rridge <- ParamSet$new(list(
  ParamDbl$new('regr.glmnet.lambda', lower = 0.001, upper = 2) 
))
tuner<-tnr('grid_search') 
terminator <- trm('evals', n_evals = 10) 
```

Autotuner learner is created for automating tuning process of given hyerparameters space for more accurate model prediction due to larger range of parameter space provided compared to default settings, which will be used for benchmark purposes reflected at the bottom of the script. Cross-validation has used to ensure every individual model are being tested to improve overall prediction accuracy.
```{r}
at_rridge <- AutoTuner$new(
  learner = glrn_rridge, 
  resampling = rsmp('cv', folds = 10), 
  measure = measure, 
  search_space = tune_lambda_rridge, 
  terminator = terminator, 
  tuner = tuner 
)

```

#### Lasso regression

Combine all the necessary data cleaning and modelling: scaling, imputation and regression learner `regr.glmnet``,  into a graph learner algorithm to facilitate prediction. 
```{r}
learner_rlasso <- lrn('regr.glmnet') 
learner_rlasso$param_set$values <- list(alpha = 1)
gr_rlasso <- po('imputemean', affect_columns=selector_type(c("numeric","integer"))) %>>%
  po('imputemode', affect_columns=selector_type("factor")) %>>%
  fencoder %>>%
  po('scale') %>>% 
  po(learner_rlasso)
glrn_rlasso <- GraphLearner$new(gr_rlasso) 
```

Train-set and Test-set RMSE used from default settings used without tuning hyperparameter is 9.56 and 9.42 respectively.
```{r}
glrn_rlasso$train(task, row_ids = train_set)
glrn_rlasso$predict(task, row_ids = train_set)$score(measure) # default lambda = 0.01, RMSE=9.56.
glrn_rlasso$predict(task, row_ids = test_set)$score(measure) # default lambda = 0.01, RMSE=9.42.

predict_rlasso <- glrn_rlasso$predict(task, row_ids=test_set) 
as.data.table(predict_rlasso) # truth = actual observation, response = predicted observations.
```

Similarly, Autotuner has the same settings as Ridge Regression's Autotuner as algorithm works the same but Lasso enables subset feature selection by imposing variables that are less important to 0 and thus, removed from model.
```{r}
tune_lambda_rlasso <- ParamSet$new(list(
  ParamDbl$new('regr.glmnet.lambda', lower = 0.001, upper = 2)
))
tuner<-tnr('grid_search') 
terminator <- trm('evals', n_evals = 10) 

at_rlasso <- AutoTuner$new(
  learner = glrn_rlasso, 
  resampling = rsmp('cv', folds = 10),
  measure = measure, 
  search_space = tune_lambda_rlasso, 
  terminator = terminator, 
  tuner = tuner 
)

```

#### Classification Regression

Combine all the necessary data cleaning and modelling: scaling, imputation and regression learner `regr.rpart``,  into a graph learner algorithm to facilitate prediction. 
```{r}
learner_rtree <- lrn("regr.rpart")

gc_rtree <- po('imputemean', affect_columns=selector_type("numeric")) %>>%
  po('imputemode', affect_columns=selector_type("factor")) %>>%
  fencoder %>>%
  po('scale') %>>%
  po(learner_rtree)

glrn_rtree <- GraphLearner$new(gc_rtree)
```

Train-set and Test-set RMSE used from default settings used without tuning hyperparameter is 13.1 and 13.5 respectively.
```{r}
glrn_rtree$train(task, row_ids = train_set)
glrn_rtree$predict(task, row_ids = train_set)$score(measure)  
glrn_rtree$predict(task, row_ids = test_set)$score(measure)  

predict_rtree <- glrn_rtree$predict(task, row_ids = test_set)  
```


Autotuner learner is created for automating tuning process of given hyerparameters space for more accurate model prediction due to larger range of parameter space provided compared to default settings, which will be used for benchmark purposes reflected at the bottom of the script. Cross-validation has used instead of train-test split due to its property of testing every individual test model.
```{r}
tune_ntrees <- ParamSet$new(list(
  ParamInt$new('min.split', lower = 10, upper = 50),
  ParamDbl$new("cp", default = 0.01, lower = 0, upper = 2)# number of trees to branch.
))

at_rtree <- AutoTuner$new(
  learner = glrn_rtree,
  resampling = rsmp('cv', folds = 10),
  measure = measure,
  search_space = tune_ntrees,
  terminator = terminator,
  tuner = tuner
)
```


#### Random Forest regression

Install and load the `ranger`` package.
```{r}
if (!("ranger" %in% installed.packages())) {
  install.packages("ranger")
}
library(ranger)
```

Combine all the necessary data cleaning and modelling: scaling, imputation and regression learner `regr.ranger``,  into a graph learner algorithm to facilitate prediction. The parameter values for random forest is node size due to its algorithm structure.
```{r}
learner_rrf <- lrn('regr.ranger') 
learner_rrf$param_set$values <- list(min.node.size = 4) 
gr_rrf <-po('imputemean', affect_columns=selector_type(c("numeric","integer"))) %>>%
  po('imputemode', affect_columns=selector_type("factor")) %>>%
  fencoder %>>%
  po('scale') %>>% 
  po(learner_rrf)
glrn_rrf <- GraphLearner$new(gr_rrf)
```

Train-set and Test-set RMSE used from default settings used without tuning hyperparameter is 9.22.
```{r}
glrn_rrf$train(task, row_ids = train_set)
glrn_rrf$predict(task, row_ids = test_set)$score(measure) # RMSE = 9.22

predict_rrf <- glrn_rrf$predict(task, row_ids=test_set) # default lambda = 0.01
as.data.table(predict_rrf) # truth = actual observation, response = predicted observations.
```

Autotuner learner is created for automating tuning process of given hyerparameters space for more accurate model prediction due to larger range of parameter space provided compared to default settings, which will be used for benchmark purposes reflected at the bottom of the script. Cross-validation has used instead of train-test split due to its property of testing every individual test model.
```{r}
tune_ntrees2 <- ParamSet$new(list(
  ParamInt$new('regr.ranger.num.trees', lower = 10, upper = 50 ) # number of trees to branch.
))

at_rrf <- AutoTuner$new(
  learner = glrn_rrf,
  resampling = rsmp('cv', folds = 10),
  measure = measure,
  search_space = tune_ntrees2,
  terminator = terminator,
  tuner = tuner
)

```

#### Gradient Boosting

Install and load the `xgboost`` package.
```{r}
if (!("xgboost" %in% installed.packages())) {
  install.packages("xgboost")
}
library(xgboost)
```

Combine all the necessary data cleaning and modelling: scaling, imputation and regression learner `regr.xgboost``,  into a graph learner algorithm to facilitate prediction. 
```{r}
learner_rgb <- lrn("regr.xgboost")

gc_rgb <- po('imputemean', affect_columns=selector_type(c("numeric","integer"))) %>>%
  po('imputemode', affect_columns=selector_type("factor")) %>>%
  fencoder %>>%
  po('scale') %>>%
  po(learner_rgb)

glrn_rgb <- GraphLearner$new(gc_rgb)
```

Train-set and Test-set RMSE used from default settings used without tuning hyperparameter is 25.73.
```{r}
glrn_rgb$train(task, row_ids = train_set)
glrn_rgb$predict(task, row_ids = test_set)$score(measure) 

predict_rgb <- glrn_rgb$predict(task, row_ids = test_set) 
```

#### Sector vector machine for regression

Combine all the necessary data cleaning and modelling: scaling, imputation and regression learner `regr.svm``,  into a graph learner algorithm to facilitate prediction. 
```{r}
learner_svr <- lrn("regr.svm")

gc_svr <- po('imputemean', affect_columns=selector_type(c("numeric","integer"))) %>>%
  po('imputemode', affect_columns=selector_type("factor")) %>>%
  fencoder %>>%
  po('scale') %>>%
  po(learner_svr)

glrn_svr <- GraphLearner$new(gc_svr)
```

Train-set and Test-set RMSE used from default settings used without tuning hyperparameter is 8.52.
```{r}
glrn_svr$train(task, row_ids = train_set)
glrn_svr$predict(task, row_ids = test_set)$score(measure) 
predict_svr <- glrn_svr$predict(task, row_ids = test_set) 
```


#### Benchmarking for comparison of above learners

Random number generater `set.seed()`` has been used to reproduce results. Benchmark has been used as it convenient by combining all the graph learners and autotuners and run it together. This facilitates comparison between different machine learning algorithm on regression prediction model and their respectively prediction accuracy (RMSE).
```{r}
set.seed(12) 

# list of regression learners
lrn_reg_list <- list(
  glrn_rlm,
  glrn_rridge,
  glrn_rlasso,
  glrn_rtree,
  glrn_rgb,
  glrn_svr,
  at_rridge,
  at_rlasso,
  at_rrf
)


bm_reg_design <- benchmark_grid(task = task, resamplings = rsmp('cv', folds = 10), learners = lrn_reg_list)
bmr_grouped <- benchmark(bm_reg_design, store_models = TRUE)

```

Install and load the `mlr3viz`` package.
```{r}
if (!("mlr3viz" %in% installed.packages())) {
  install.packages("mlr3viz")
}
library(mlr3viz)
```

Plot the benchmarked results to compare its aggregated prediction accuracy (RMSE) across all machine learning methods used. It can be seen that Sector Vector Regressor has the lowest RMSE of 9.77 compared to other models.
```{r}
autoplot(bmr_grouped, measure = measure) + theme(axis.text.x = element_text(angle = 60, hjust = 1)) 
bmr_grouped$aggregate(measure)
bmr_grouped$score(measure)
```


References:
Citizensadvice.org.uk. 2022. Claim compensation if your flight's delayed or cancelled. [online] Available at: <https://www.citizensadvice.org.uk/consumer/holiday-cancellations-and-compensation/if-your-flights-delayed-or-cancelled/> [Accessed 12 March 2022]. 